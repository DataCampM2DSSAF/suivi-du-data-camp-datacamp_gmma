First week :

Objectives :
	- discover the main ideas about the project 
	- use new tools : GitHub, Kaggle
	
Because we are not really familiar with GitHub and Kaggle, one of the first thing was to start using them.
Kaggle permits to find all the data for differents projects. Moreover, some notebooks are available and useful to show us different ideas to solve the problem.
GitHub is useful to write code in a team, as each member can see the other codes, add his own code, and put other files, for instance a notebook where one can find explanations about the code, the subject, ...

The data we have or about little games used by children to evaluate their skill. 
The main objective is, according to these data, to evaluate as good they are by giving a mark in 0, 1, 2 or 3.


Second week : 

Objectives :
	- understand data -> what is the target, what are the different files, ...
	- divide tasks -> what each team member have to do
	- first Kaggle submission -> at least one of us must submit a model
	- set up Github -> make a clear difference between Readme, code and notebook
	
Because understanding data is more difficult than we thought at the first time, it is not so easy to still divide tasks.
We started to submit something on Kaggle just to see how Kaggle works, what we have to put in it, ...
Concerning the GitHub, we started to make the difference between Readme, code and notebook. However, some things are still not clear for us, so we will speak with our teacher next session.
The main problem we get is to get the accuracy_group, which is the mark for each child. It seems to be a big problem for every team. The good point is that some teams already gave their advices and code in some notebooks, and we can use them to try to solve this problem.
To get marks, we need to use words 'correct":true' or 'correct":false' for each game_session. These words are foud in 'event_data', a variable from the training and testing sets.


Third week :

Objectives :
	- continue to understand how to get the accuracy in the train file
	- each team member have to submit something on Kaggle
	
All of us have submit a random result on Kaggle. 
We continue to understand the meaning of the the words 'correct":true' and 'correct":false'. 
Indeed, they are not only used when someone fail or win a game, that is why to count the number of fails and wins by gam session, we have to filter the data not only by game session.
It is the last problem we have to create a file in the asked format, e.g. a file such as train_labels.csv, where there is the game session id, the number of fails and wins, the accurac group, ...
After creating this file, we will have to start writing an explanation of data files, main variables, ... and clean the data.


Based on the isues primesly presented we wrote a function to build the labels in the train file. 
We selected the lines where the event_code was 4100 or 4110: they correspond to the final events of game_session.
Then we applied the groupby function to the event_session column.
Finaly we counted the numbers of correct and incorrect attempts: the information is available in the event_data column: 
if the string 'correct:true' is present  it's a success, if not it's a failure.

Two main isues:
	1.Into the lines with the 4100/4110 event_code there are still lines with no information about the results of the assesment in the event_data column.
	2.We have to pedict on how many attemps every child will sucess an assignement. The issue is there are mny game_session for one installation_id.
	Moreover, is this best to make the prediction for every account and every type of game ? 
