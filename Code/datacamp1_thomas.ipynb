{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data vizualisation\nimport seaborn as sns # data vizualisation\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"root = '/kaggle/input/data-science-bowl-2019/'\n\nprint('Reading train.csv file ...', end='')\ntrain = pd.read_csv(root + 'train.csv')  # training data\nprint(' Done!')\n\nprint('Reading train_labels.csv file ...', end='')\ntrain_labels = pd.read_csv(root + 'train_labels.csv') \nprint(' Done!')\n\nprint('Reading test.csv file ...', end='')\ntest = pd.read_csv(root + 'test.csv')\nprint(' Done!')\n\nprint('Reading specs.csv file ...', end='')\nspecs = pd.read_csv(root + 'specs.csv')\nprint(' Done!')\n\nprint('Reading sample_submission.csv file ...', end='')\nsample_sub = pd.read_csv(root + 'sample_submission.csv')\nprint(' Done!')\n\nprint('All data imported')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t Shapes:')\nprint('train.csv \\t - {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\nprint('train_labels.csv - {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\nprint('test.csv \\t - {} rows and {} columns'.format(test.shape[0], test.shape[1]))\nprint('specs.csv \\t - {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\nprint('sample_sub.csv \\t - {} rows and {} columns'.format(sample_sub.shape[0], sample_sub.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What variables do we have ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These are the main data files which contain the gameplay events.\n\n* `event_id` - Randomly generated unique identifier for the event type. Maps to `event_id` column in **specs** table.\n* `game_session` - Randomly generated unique identifier grouping events within a single game or video play session.\n* `timestamp` - Client-generated datetime \n* `event_data` - Semi-structured JSON formatted string containing the events parameters. Default fields are: `event_count`, `event_code`, and `game_time`; otherwise fields are determined by the event type.\n* `installation_id` - Randomly generated unique identifier grouping game sessions within a single installed application instance.\n* `event_count` - Incremental counter of events within a game session (offset at 1). Extracted from `event_data`.\n* `event_code` - Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from `event_data`.\n* `game_time` - Time in milliseconds since the start of the game session. Extracted from `event_data`.\n* `title` - Title of the game or video.\n* `type` - Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.\n* `world` - The section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length/Height), 'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight)."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.to_datetime(train['timestamp'].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**train_labels** is a transformation of the **train** data, on which we can train our models.\nIt seems that, in order to create a proper **train_labels** data frame, all the information we need to extract from **train** is in the `event_data` column."},{"metadata":{},"cell_type":"markdown","source":"The outcomes in this competition are grouped into 4 groups (labeled `accuracy_group` in the data):\n* 3 : the assessment was solved on the first attempt     : `accuracy` = 1.0\n* 2 : the assessment was solved on the second attempt    : `accuracy` = 0.5\n* 1 : the assessment was solved after 3 or more attempts : 0 < `accuracy` < 0.5\n* 0 : the assessment was never solved                    : `accuracy` = 0.0\n"},{"metadata":{},"cell_type":"markdown","source":"What does the submission should look like:"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because the training data is so large, we will take a random sample of it for plotting. Since we are doing this at random it will speed up the time it takes to plot, and should still give us a a good view of the data's format."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ = train.sample(100000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have to find how to create the variables `num_correct` and `num_incorrect` in order to create `accuracy` and then `accuracy_group`.\n\nFor that, whenever ***\"correct\":true*** appears in the column `event_data`, it means that that player succeed the current event (recognizable by `event_id`). In the same way, whenever ***\"correct\":false*** appears in the column `event_data` it means that that player failed the current event.\n\nSo, we're looking for the number of appearances of ***\"correct\":true*** and ***\"correct\":false*** in the same `game_session`."},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_labels(data):\n    \"\"\"\n    Input : Data in the same shape as train.csv\n    Output : Data in the same shape as train_labels.csv\n    \"\"\"\n    # Which rows concerns assessments ?\n    mask_assessment = data['event_data'].str.contains('event_code\":4100') | data['event_data'].str.contains('event_code\":4110')\n    # Which rows contains correct assessments ?\n    mask_correct = data.loc[mask_assessment,'event_data'].str.contains('correct\":true')\n    # Which rows contains incorrect assessments ?\n    mask_incorrect = data.loc[mask_assessment,'event_data'].str.contains('correct\":false')\n\n    \n    \n    \n    \n    num_correct = pd.DataFrame(data[data['event_data'].str.contains('correct\":true')].groupby('game_session').count()[\"event_id\"].rename('num_correct'))\n    num_incorrect = pd.DataFrame(data[data['event_data'].str.contains('correct\":false')].groupby('game_session').count()[\"event_id\"].rename('num_incorrect'))\n\n    labels_ = pd.DataFrame(num_correct.merge(num_incorrect, how='outer', left_on=num_correct.index, right_on=num_incorrect.index)).fillna(0)\n    labels_ = labels_.rename(columns={'key_0':'game_session', 'num_correct_x':'num_correct', 'num_correct_y':'num_incorrect'})\n    labels_ = labels_.merge(train_[['installation_id', 'game_session', 'title']], how='inner', left_on='game_session', right_on='game_session')\n    labels_ = labels_.drop_duplicates()\n    \n    labels_[\"accuracy\"] = labels_[\"num_correct\"]/(labels_[\"num_correct\"]+labels_[\"num_incorrect\"])\n    labels_[\"accuracy_group\"] = labels_[\"accuracy\"].apply(lambda x: 0 if x==0 else (1 if x<0.5 else (2 if x<0.9 else 3)))\n    \n    return labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_assessment = train_['event_data'].str.contains('event_code\":4100') | train_['event_data'].str.contains('event_code\":4100')\nmask_correct = train_.loc[mask_assessment,'event_data'].str.contains('correct\":true')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_.loc[mask_assessment, 'event_data'].str.contains('correct\":true')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_correct = pd.DataFrame('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['event_data'].str.contains('correct\":true')].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train['game_session'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_[train_['event_data'].str.contains('true')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train_[train_['event_data'].str.contains('true')]          - "},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_ = make_labels(train_)\nlabels_['num_correct'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_ = pd.DataFrame(num_correct.merge(num_incorrect, how='outer', left_on=num_correct.index, right_on=num_incorrect.index)).fillna(0)\nlabels_ = labels_.rename(columns={'key_0':'game_session', 'num_correct_x':'num_correct', 'num_correct_y':'num_incorrect'})\nlabels_[\"accuracy\"] = labels_[\"num_correct\"]/(labels_[\"num_correct\"]+labels_[\"num_incorrect\"])\nlabels_[\"accuracy_group\"] = labels_[\"accuracy\"].apply(lambda x: 0 if x==0 else (1 if x<0.5 else (2 if x<0.9 else 3)))\nlabels_ = labels_.merge(train_[['installation_id', 'game_session', 'title']], how='inner', left_on='game_session', right_on='game_session')\nlabels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_[['installation_id', 'title']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t Lengths:')\nprint('num_correct   - {} rows'.format(num_correct.shape[0]))\nprint('labels_   - {} rows'.format(labels_.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_correct.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_correct.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_correct = train_[train_['event_data'].str.contains('correct\":true')].groupby('game_session').count().iloc[:,0]\nnum_incorrect = train_[train_['event_data'].str.contains('correct\":false')].groupby('game_session').count().iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t Lengths:')\nprint('num_correct   - {} rows'.format(num_correct.shape[0]))\nprint('num_incorrect - {} rows'.format(num_incorrect.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.merge(train_, num_correct, on='game_session')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mt = MainTransformer()\nft = FeatureTransformer()\ntransformers = {'ft': ft}\nregressor_model1 = RegressorModel(model_wrapper=LGBWrapper_regr())\nregressor_model1.fit(X=reduce_train, y=y, folds=folds, params=params, preprocesser=mt, transformers=transformers,\n                    eval_metric='cappa', cols_to_drop=cols_to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from functools import partial\nimport scipy as sp\nclass OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa (QWK) score\n    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n        return -qwk(y, X_p)\n\n    def fit(self, X, y):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n\n    def coefficients(self):\n        \"\"\"\n        Return the optimized coefficients\n        \"\"\"\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npr1 = regressor_model1.predict(reduce_train)\n\noptR = OptimizedRounder()\noptR.fit(pr1.reshape(-1,), y)\ncoefficients = optR.coefficients()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt_preds = optR.predict(pr1.reshape(-1, ), coefficients)\nqwk(y, opt_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# some coefficients calculated by me.\npr1 = regressor_model1.predict(reduce_test)\npr1[pr1 <= 1.12232214] = 0\npr1[np.where(np.logical_and(pr1 > 1.12232214, pr1 <= 1.73925866))] = 1\npr1[np.where(np.logical_and(pr1 > 1.73925866, pr1 <= 2.22506454))] = 2\npr1[pr1 > 2.22506454] = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['accuracy_group'] = pr1.astype(int)\nsample_submission.to_csv('submission.csv', index=False)\n\nsample_submission['accuracy_group'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}